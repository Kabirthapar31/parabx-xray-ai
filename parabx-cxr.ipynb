{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r8Dj7klJAL6-"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "# If folder doesn't exist, create it\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "# Now copy the file: path should match where you uploaded it\n",
        "shutil.copy(\"/content/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle --quiet\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Move kaggle.json to the right location\n",
        "shutil.copy(\"/content/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "# Download and extract the CXR dataset\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip -q chest-xray-pneumonia.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaabHLt2BDlc",
        "outputId": "f15ba67f-34e6-40f7-acf7-4c93670eb98b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            " 99% 2.28G/2.29G [00:17<00:00, 269MB/s]\n",
            "100% 2.29G/2.29G [00:17<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    'chest_xray/train', target_size=(224,224), batch_size=32, class_mode='binary')\n",
        "val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    'chest_xray/val', target_size=(224,224), batch_size=32, class_mode='binary')\n",
        "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    'chest_xray/test', target_size=(224,224), batch_size=32, class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHd05evIBjdy",
        "outputId": "fa1b2f35-cf15-4c06-f3ec-5c59e52f6095"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
        "base.trainable = False\n",
        "model = tf.keras.Sequential([\n",
        "    base,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho8aMhTjBqSx",
        "outputId": "f3ae5dc7-f757-4a27-b8bd-8d3c9bbd1c69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen, validation_data=val_gen, epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwbsX4WyBvuR",
        "outputId": "43a2c6fd-9e36-4e29-a785-399eb0a7e6f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 332ms/step - accuracy: 0.8303 - loss: 0.3711 - val_accuracy: 0.7500 - val_loss: 0.4910\n",
            "Epoch 2/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 301ms/step - accuracy: 0.9611 - loss: 0.1311 - val_accuracy: 0.8750 - val_loss: 0.4205\n",
            "Epoch 3/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 298ms/step - accuracy: 0.9649 - loss: 0.1060 - val_accuracy: 0.8750 - val_loss: 0.3812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bce6c77bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_gen)\n",
        "print(f'Test accuracy: {acc:.2%}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx6JIma2CaKm",
        "outputId": "8cba1fdd-f72f-419a-a731-4f4462d4ca37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - accuracy: 0.8066 - loss: 0.4454\n",
            "Test accuracy: 81.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cxr_pneumonia_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ud9gE97CgFY",
        "outputId": "e68403b0-1f28-4361-a3b4-dc2a6dd2cfaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oaqcycTIC7Ez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}